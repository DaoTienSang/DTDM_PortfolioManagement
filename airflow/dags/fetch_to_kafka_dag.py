from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
from kafka import KafkaProducer
from vnstock import Vnstock
import json
import pandas as pd
import numpy as np
import time
import requests
import socket
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# Class gi√∫p x·ª≠ l√Ω numpy v√† pandas datatype trong json
class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        if isinstance(obj, pd.Timestamp):
            return obj.strftime('%Y-%m-%d %H:%M:%S')
        return super(NpEncoder, self).default(obj)

def fetch_and_push_to_kafka():
    # Thi·∫øt l·∫≠p Socket timeout d√†i h∆°n ƒë·ªÉ cho ph√©p DNS resolution
    socket.setdefaulttimeout(60)  # 60 gi√¢y timeout
    
    # Thi·∫øt l·∫≠p session v·ªõi retry
    session = requests.Session()
    retry_strategy = Retry(
        total=5,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["HEAD", "GET", "OPTIONS", "POST"]
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)
    
    # Th·ª≠ ping Google DNS ƒë·ªÉ ki·ªÉm tra k·∫øt n·ªëi internet
    try:
        session.get("https://8.8.8.8", timeout=5)
        print("‚úÖ K·∫øt n·ªëi internet OK")
    except Exception as e:
        print(f"‚ö†Ô∏è Ki·ªÉm tra k·∫øt n·ªëi internet th·∫•t b·∫°i: {e}")
    
    # Th√™m retry v√† timeout d√†i h∆°n
    max_retries = 3
    retry_delay = 30  # seconds
    
    # Danh s√°ch c√°c m√£ c·ªï phi·∫øu ph·ªï bi·∫øn (VN30 v√† m·ªôt s·ªë blue-chip kh√°c)
    popular_symbols = [
        # VN30
        "VCB", "VIC", "VHM", "HPG", "BID", "VNM", "FPT", "MSN", "MWG", "TCB",
        "CTG", "VPB", "NVL", "VRE", "GAS", "SAB", "PLX", "STB", "POW", "HDB",
        "VJC", "TPB", "ACB", "PDR", "BCM", "BVH", "GVR", "SSI", "KDH", "LPB",
        # Th√™m m·ªôt s·ªë blue-chip kh√°c
        "DHG", "VGC", "VSH", "REE", "HAG", "DXG", "KBC", "VGT", "HBC", "GMD",
        # Th√™m c√°c m√£ theo y√™u c·∫ßu
        "FRT", "NKG", "NLG", "PNJ", "PVD", "PVS", "VHC"
    ]
    
    try:
        vnstock_instance = Vnstock()
        stock = vnstock_instance.stock(symbol='VN30', source='VCI')
        
        # S·ª≠ d·ª•ng c√°c m√£ ph·ªï bi·∫øn ƒë√£ ƒë·ªãnh nghƒ©a thay v√¨ l·∫•y t·∫•t c·∫£
        symbols = popular_symbols
        
        # L·∫•y gi√° hi·ªán t·∫°i cho c√°c m√£ ph·ªï bi·∫øn
        price_board = stock.trading.price_board(symbols_list=symbols)
        
    except Exception as e:
        print(f"‚ùå L·ªói khi k·∫øt n·ªëi ƒë·∫øn API: {str(e)}")
        # S·ª≠ d·ª•ng danh s√°ch m√£ ph·ªï bi·∫øn n·∫øu kh√¥ng l·∫•y ƒë∆∞·ª£c gi√°
        symbols = popular_symbols
        # Tr·∫£ v·ªÅ n·∫øu kh√¥ng ti·∫øp t·ª•c x·ª≠ l√Ω ƒë∆∞·ª£c
        if not hasattr(locals(), 'price_board'):
            print("‚ùå Kh√¥ng th·ªÉ l·∫•y ƒë∆∞·ª£c b·∫£ng gi√°, d·ª´ng x·ª≠ l√Ω")
            return

    if isinstance(price_board.columns, pd.MultiIndex):
        price_board.columns = ['_'.join(map(str, col)).strip() for col in price_board.columns.values]

    # T·∫°o dictionary ƒë·ªÉ l∆∞u tr·ªØ th√¥ng tin t·ª´ price_board theo symbol
    price_board_dict = {}
    for _, row in price_board.iterrows():
        symbol = row.get('listing_symbol')
        if symbol:
            price_board_dict[symbol] = {
                'current_price': row.get('match_match_price', 0),
                'ceiling': row.get('listing_ceiling', 0),
                'floor': row.get('listing_floor', 0),
                'vol': row.get('match_match_vol', 0)
            }

    snapshot = {'time': datetime.now().isoformat()}
    for symbol in symbols:
        try:
            row = price_board[price_board['listing_symbol'] == symbol]
            snapshot[symbol] = row['match_match_price'].values[0] if not row.empty else None
        except Exception:
            snapshot[symbol] = None

    producer = KafkaProducer(
        bootstrap_servers='kafka:9092',
        value_serializer=lambda v: json.dumps(v, cls=NpEncoder).encode('utf-8'),
        batch_size=16384,  # TƒÉng k√≠ch th∆∞·ªõc batch
        buffer_memory=67108864  # TƒÉng b·ªô ƒë·ªám l√™n 64MB
    )

    # G·ª≠i d·ªØ li·ªáu gi√° hi·ªán t·∫°i v√†o Kafka
    producer.send('stock-topic', snapshot)
    print("‚úÖ ƒê√£ ƒë·∫©y d·ªØ li·ªáu gi√° hi·ªán t·∫°i v√†o Kafka topic `stock-topic`")
    
    # L·∫•y v√† g·ª≠i d·ªØ li·ªáu l·ªãch s·ª≠ v√†o Kafka
    # S·ª≠ d·ª•ng c√°c m√£ ph·ªï bi·∫øn ƒë√£ ƒë·ªãnh nghƒ©a
    sample_symbols = symbols
    
    # Chia th√†nh c√°c batch nh·ªè h∆°n ƒë·ªÉ x·ª≠ l√Ω song song
    batch_size = 3  # X·ª≠ l√Ω 3 m√£ m·ªói batch
    symbol_batches = [sample_symbols[i:i+batch_size] for i in range(0, len(sample_symbols), batch_size)]
    
    print(f"S·∫Ω x·ª≠ l√Ω {len(sample_symbols)} m√£ c·ªï phi·∫øu trong {len(symbol_batches)} batch")
    
    for batch_idx, symbol_batch in enumerate(symbol_batches):
        print(f"X·ª≠ l√Ω batch {batch_idx+1}/{len(symbol_batches)} v·ªõi {len(symbol_batch)} m√£...")
        
        for symbol in symbol_batch:
            try:
                print(f"üîÑ ƒêang l·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol}...")
                
                # Th√™m retry cho API history
                for history_attempt in range(max_retries):
                    try:
                        # L·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ t·ª´ 2020 ƒë·∫øn hi·ªán t·∫°i
                        historical_data = stock.quote.history(
                            symbol=symbol,
                            start='2020-01-01', 
                            end=datetime.now().strftime('%Y-%m-%d'),
                            interval='1D'
                        )
                        break  # N·∫øu th√†nh c√¥ng, tho√°t kh·ªèi v√≤ng l·∫∑p retry
                    except Exception as e:
                        print(f"‚ùå L·ªói khi l·∫•y l·ªãch s·ª≠ {symbol} (l·∫ßn {history_attempt+1}/{max_retries}): {str(e)}")
                        if history_attempt < max_retries - 1:
                            print(f"‚è± ƒê·ª£i {retry_delay} gi√¢y tr∆∞·ªõc khi th·ª≠ l·∫°i...")
                            time.sleep(retry_delay)
                        else:
                            print(f"‚ùå ƒê√£ h·∫øt s·ªë l·∫ßn th·ª≠ l·∫°i. B·ªè qua m√£ {symbol}.")
                            raise  # Re-raise ƒë·ªÉ x·ª≠ l√Ω ·ªü except b√™n ngo√†i
                
                # L·∫•y gi√° hi·ªán t·∫°i t·ª´ snapshot
                current_price = snapshot.get(symbol)
                
                # L·∫•y th√¥ng tin tr·∫ßn, s√†n, kh·ªëi l∆∞·ª£ng t·ª´ price_board_dict
                symbol_info = price_board_dict.get(symbol, {})
                ceiling = symbol_info.get('ceiling', 0)
                floor = symbol_info.get('floor', 0)  
                vol = symbol_info.get('vol', 0)
                
                print(f"‚úÖ Th√¥ng tin cho {symbol}: Gi√° hi·ªán t·∫°i={current_price}, Tr·∫ßn={ceiling}, S√†n={floor}, Kh·ªëi l∆∞·ª£ng={vol}")
                
                # Chuy·ªÉn th√†nh dictionary ƒë·ªÉ serialize - x·ª≠ l√Ω ƒë√∫ng ki·ªÉu d·ªØ li·ªáu
                if not historical_data.empty:
                    # Convert DataFrame to dict with Python native types 
                    records = []
                    for _, row in historical_data.iterrows():
                        record = {}
                        for col, val in row.items():
                            if isinstance(val, (np.integer, np.int64, np.int32)): 
                                record[col] = int(val)
                            elif isinstance(val, (np.floating, np.float64, np.float32)):
                                record[col] = float(val)
                            elif isinstance(val, pd.Timestamp):
                                record[col] = val.strftime('%Y-%m-%d')
                            else:
                                record[col] = val
                        records.append(record)
                    
                    # Th√™m th√¥ng tin m·ªõi v√†o historical_dict
                    historical_dict = {
                        'symbol': symbol,
                        'current_price': current_price,
                        'ceiling': ceiling,
                        'floor': floor,
                        'vol': vol,
                        'historical_data': records
                    }
                    
                    # G·ª≠i v√†o Kafka
                    producer.send('stock-history-topic', historical_dict)
                    print(f"‚úÖ ƒê√£ ƒë·∫©y d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol} v√†o Kafka topic `stock-history-topic`")
                    
                    # Th√™m delay ƒë·ªÉ tr√°nh gi·ªõi h·∫°n API
                    time.sleep(5)
                
            except Exception as e:
                print(f"‚ùå L·ªói khi l·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol}: {str(e)}")
                # N·∫øu g·∫∑p l·ªói gi·ªõi h·∫°n API, ch·ªù th√™m ƒë·ªÉ tr√°nh b·ªã block
                if "qu√° nhi·ªÅu request" in str(e).lower():
                    print("‚è± ƒêang ch·ªù 30 gi√¢y ƒë·ªÉ tr√°nh gi·ªõi h·∫°n API...")
                    time.sleep(30)
        
        # Sau m·ªói batch, ch·ªù m·ªôt ch√∫t ƒë·ªÉ ƒë·∫£m b·∫£o API kh√¥ng b·ªã qu√° t·∫£i
        if batch_idx < len(symbol_batches) - 1:
            print(f"‚è± ƒê√£ x·ª≠ l√Ω xong batch {batch_idx+1}, ƒëang ch·ªù 20 gi√¢y tr∆∞·ªõc khi x·ª≠ l√Ω batch ti·∫øp theo...")
            time.sleep(20)  # TƒÉng th·ªùi gian ch·ªù t·ª´ 15 l√™n 20 gi√¢y
        
        # N·∫øu ƒë√£ x·ª≠ l√Ω qu√° 100 m√£, d·ª´ng l·∫°i
        if (batch_idx + 1) * batch_size >= 100:
            print(f"üõë ƒê√£ x·ª≠ l√Ω ƒë·ªß 100 m√£ c·ªï phi·∫øu, d·ª´ng x·ª≠ l√Ω.")
            break
    
    producer.flush()
    print("‚úÖ Ho√†n th√†nh vi·ªác ƒë·∫©y d·ªØ li·ªáu v√†o Kafka")

default_args = {
    'owner': 'airflow',
    'retries': 3,  # TƒÉng s·ªë l·∫ßn retry c·ªßa task
    'retry_delay': timedelta(minutes=5),  # TƒÉng th·ªùi gian gi·ªØa c√°c l·∫ßn retry
    'start_date': datetime(2023, 5, 1),
    'depends_on_past': False,  # Th√™m depends_on_past = False
    'execution_timeout': timedelta(minutes=30),  # Th√™m timeout cho task
}

with DAG(
    dag_id='fetch_stock_to_kafka',
    default_args=default_args,
    schedule_interval='@once',  # Thay ƒë·ªïi th√†nh @once ƒë·ªÉ ch·∫°y m·ªôt l·∫ßn khi Airflow kh·ªüi ƒë·ªông
    catchup=False,
    max_active_runs=1,  # Th√™m ƒë·ªÉ ch·ªâ cho ph√©p 1 instance c·ªßa DAG ch·∫°y c√πng l√∫c
    tags=['stock', 'vnstock', 'kafka'],
) as dag:
    task = PythonOperator(
        task_id='fetch_push_kafka',
        python_callable=fetch_and_push_to_kafka,
        execution_timeout=timedelta(minutes=25),  # Th√™m timeout ri√™ng cho task n√†y
    )